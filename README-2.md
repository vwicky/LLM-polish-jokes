# version 2 preparations

## DATA

First, I'd like to gather more data. I utilized "Perelki" and got approximatly ~4500 jokes. I'd like to obtain at least ~1500 more. I have left some pages of Perelki unscrapped, so I'll do them and then go on to find more sources. 

## MODEL

Maybe, just maybe, papuGaPT-2 - despite being quite good - is too small for this task and, as I've laid my hands on Kaggle's GPU p100 I am able to train begger models faster, I want to change a model for a bigger one.

I settled on: **[https://huggingface.co/szymonrucinski/Krakowiak-7B-v2?source=post_page-----166ee77f8b60---------------------------------------](szymonrucinski/Krakowiak-7B-v2)**

articles I used:
1. https://medium.com/thelion-ai/landscape-of-polish-llms-166ee77f8b60
2. 